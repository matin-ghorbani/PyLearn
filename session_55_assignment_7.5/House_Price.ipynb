{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/emanhamed/Houses-dataset"
      ],
      "metadata": {
        "id": "JMucNtzUCOom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d485dee2-4750-4249-b37c-c34fa20d1dd5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Houses-dataset'...\n",
            "remote: Enumerating objects: 2166, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 2166 (delta 0), reused 0 (delta 0), pack-reused 2165\u001b[K\n",
            "Receiving objects: 100% (2166/2166), 176.26 MiB | 39.50 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "Updating files: 100% (2144/2144), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import locale\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, load_model\n",
        "from keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.activations import relu, linear\n",
        "from keras.losses import mean_absolute_percentage_error\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "x0nde80VbmtJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH: str = '/content/Houses-dataset/Houses Dataset'\n",
        "MODEL_PATH_TO_SAVE: str = '/content/drive/MyDrive/weights/house_pricing_best.keras'\n",
        "TEST_IMAGES_DIRECTORY: str = '/content/test_images'"
      ],
      "metadata": {
        "id": "6mbqNB1qb-Sb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "Tzsew4_VbiXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_house_images(df: pd.DataFrame, input_path: str) -> np.ndarray:\n",
        "    images = []\n",
        "\n",
        "    for i in tqdm(df.index.values):\n",
        "\n",
        "        base_path = os.path.sep.join([input_path, f'{i + 1}_*'])\n",
        "        house_paths = sorted(list(\n",
        "            glob.glob(base_path)\n",
        "        ))\n",
        "\n",
        "        input_images = []\n",
        "        output_images = np.zeros((64, 64, 3), dtype='uint8')\n",
        "\n",
        "        for house_path in house_paths:\n",
        "            image = cv.imread(house_path)\n",
        "            image = cv.resize(image, (32, 32))\n",
        "            image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "            input_images.append(image)\n",
        "\n",
        "        output_images[0:32, 0:32] = input_images[0]\n",
        "        output_images[0:32, 32:64] = input_images[1]\n",
        "        output_images[32:64, 32:64] = input_images[2]\n",
        "        output_images[32:64, 0:32] = input_images[3]\n",
        "\n",
        "        images.append(output_images)\n",
        "\n",
        "    return np.array(images)"
      ],
      "metadata": {
        "id": "dnYtATY2bpcY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_house_attributes(input_path: str) -> pd.DataFrame:\n",
        "    columns = ['bedrooms', 'bathrooms', 'area', 'zipcode', 'price']\n",
        "    df = pd.read_csv(input_path, sep=\" \", header=None, names=columns)\n",
        "\n",
        "    zipcodes = df['zipcode'].value_counts().keys().tolist()\n",
        "    counts = df['zipcode'].value_counts().tolist()\n",
        "\n",
        "    for zipcode, count in tqdm(zip(zipcodes, counts)):\n",
        "        if count < 25:\n",
        "            index = df[df['zipcode'] == zipcode].index\n",
        "            df.drop(index, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "WQSFLQL-bsh4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn(width: int, height: int, depth: int, filters: tuple[int, int, int] = (16, 32, 64), regress: bool = False) -> Sequential:\n",
        "    input_shape = (height, width, depth)\n",
        "    chan_dim = -1\n",
        "\n",
        "    model: Sequential = Sequential()\n",
        "    for i, f in tqdm(enumerate(filters)):\n",
        "\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv2D(f, (3, 3), padding='same',\n",
        "                      input_shape=input_shape, activation=relu))\n",
        "\n",
        "        else:\n",
        "            model.add(layers.Conv2D(f, (3, 3), padding='same', activation=relu))\n",
        "\n",
        "        model.add(layers.BatchNormalization(axis=chan_dim))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(16, activation=relu))\n",
        "    model.add(layers.BatchNormalization(axis=chan_dim))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(4, activation=relu))\n",
        "\n",
        "    if regress:\n",
        "        model.add(layers.Dense(1, activation=linear))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "KE2Zy4-KbvQt"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "3aFAMUxSb3r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('[INFO] loading house attributes...')\n",
        "input_path = os.path.sep.join([DATASET_PATH, 'HousesInfo.txt'])\n",
        "df = load_house_attributes(input_path)\n",
        "print('\\n[INFO] loading house attributes done.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lju2YbDdar6m",
        "outputId": "2b32b9e1-d622-45ea-b1b3-c3c95c3fc325"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading house attributes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "49it [00:00, 1228.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] loading house attributes done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('[INFO] loading house images...')\n",
        "images = load_house_images(df, DATASET_PATH)\n",
        "images = images / 255.\n",
        "train_attr_x, test_attr_x, train_images_x, test_images_x = train_test_split(\n",
        "    df, images, test_size=.2, random_state=42\n",
        ")\n",
        "print('\\n[INFO] loading house images done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w23mp-zrcaMg",
        "outputId": "e97267f0-4fc1-4cc0-9ce8-ed01ecbe142f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading house images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 362/362 [00:10<00:00, 35.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] loading house images done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_price = train_attr_x['price'].max()\n",
        "y_train = train_attr_x['price'] / max_price\n",
        "y_test = test_attr_x['price'] / max_price"
      ],
      "metadata": {
        "id": "pdxy5d9Vcom-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('[INFO] creating the model...')\n",
        "model = create_cnn(64, 64, 3, regress=True)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), #, decay=1e-3 / 200),\n",
        "              loss=mean_absolute_percentage_error)\n",
        "checkpoint = ModelCheckpoint(MODEL_PATH_TO_SAVE, save_best_only=True)\n",
        "print('\\n[INFO] creating the model done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NcyvvajdJjW",
        "outputId": "a5a7a9bb-41c0-4c44-dfbf-1628ef9e5aab"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] creating the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3it [00:00, 33.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] creating the model done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('[INFO] training model...')\n",
        "model.fit(\n",
        "    x=train_images_x,\n",
        "    y=y_train,\n",
        "    validation_data=(test_images_x, y_test),\n",
        "    epochs=200,\n",
        "    batch_size=8,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "print('[INFO] training model done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZMe2CzjdNA0",
        "outputId": "993b9a65-059f-4b9b-f351-58da229c3a64"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model...\n",
            "Epoch 1/200\n",
            "37/37 [==============================] - 4s 20ms/step - loss: 1503.7213 - val_loss: 1320.0948\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1021.3154 - val_loss: 3942.3376\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1018.7276 - val_loss: 4610.8052\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 708.1383 - val_loss: 4105.4624\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 590.7356 - val_loss: 2533.7319\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 386.6475 - val_loss: 1705.5995\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 322.0567 - val_loss: 1483.2529\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 278.5504 - val_loss: 1134.1636\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 275.4168 - val_loss: 703.1582\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 246.1462 - val_loss: 547.2107\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 187.5860 - val_loss: 379.1606\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 170.9707 - val_loss: 332.5721\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 138.2596 - val_loss: 285.7012\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 166.0105 - val_loss: 237.4806\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 135.6460 - val_loss: 172.8948\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 121.1936 - val_loss: 110.1824\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 121.0804 - val_loss: 94.0175\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 101.5703 - val_loss: 94.1537\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 94.2600 - val_loss: 90.0821\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 87.7089 - val_loss: 83.5848\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 78.2796 - val_loss: 80.6890\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 83.0153 - val_loss: 78.2806\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 64.4000 - val_loss: 84.6561\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 77.8032 - val_loss: 70.8223\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 75.0546 - val_loss: 67.7925\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 69.7564 - val_loss: 81.5297\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 68.5589 - val_loss: 72.2677\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 66.5241 - val_loss: 76.4480\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 62.2721 - val_loss: 74.5481\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 79.4500 - val_loss: 73.2615\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 62.8854 - val_loss: 65.5723\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 61.5691 - val_loss: 67.5909\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 58.3310 - val_loss: 65.8857\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 69.4833 - val_loss: 68.4409\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 58.3404 - val_loss: 71.5617\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 62.7649 - val_loss: 65.6512\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 1s 14ms/step - loss: 59.6612 - val_loss: 63.4896\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 52.3054 - val_loss: 66.7222\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 56.6816 - val_loss: 71.1540\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 57.7023 - val_loss: 66.9417\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 53.4685 - val_loss: 51.6964\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 54.7765 - val_loss: 53.0903\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 49.9522 - val_loss: 60.5368\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 64.2647 - val_loss: 75.9701\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 52.6060 - val_loss: 75.9370\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 53.0572 - val_loss: 60.6388\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 52.1214 - val_loss: 54.8628\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 54.8170 - val_loss: 57.4373\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 50.0062 - val_loss: 52.2085\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 51.0735 - val_loss: 61.3865\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 52.1030 - val_loss: 61.2564\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 49.1028 - val_loss: 50.5054\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 48.2888 - val_loss: 60.6741\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 49.1816 - val_loss: 63.1073\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 51.7822 - val_loss: 57.7237\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 49.5991 - val_loss: 64.8415\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 49.4822 - val_loss: 60.8442\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 53.8770 - val_loss: 66.0623\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 54.2554 - val_loss: 64.3162\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 47.4601 - val_loss: 65.8189\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 46.0534 - val_loss: 65.7116\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 48.9602 - val_loss: 68.1909\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 47.6062 - val_loss: 69.0203\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 50.4285 - val_loss: 69.7375\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 47.2946 - val_loss: 68.2213\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 47.4915 - val_loss: 71.4676\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 43.9076 - val_loss: 74.5988\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 52.0559 - val_loss: 68.9032\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 47.0478 - val_loss: 70.1401\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 52.8036 - val_loss: 63.3842\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 47.8582 - val_loss: 67.1812\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 50.4742 - val_loss: 54.2600\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 49.8082 - val_loss: 50.5028\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 46.1862 - val_loss: 62.9786\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 53.1964 - val_loss: 73.8610\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 46.5871 - val_loss: 74.9886\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 45.4978 - val_loss: 89.1136\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 44.7848 - val_loss: 75.9141\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 49.0892 - val_loss: 87.9923\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 51.1871 - val_loss: 68.6530\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 55.4626 - val_loss: 51.6358\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 48.8521 - val_loss: 53.9284\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 48.8029 - val_loss: 53.8200\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 45.7468 - val_loss: 69.5571\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 47.3670 - val_loss: 76.8814\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 51.5908 - val_loss: 71.4212\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 44.9485 - val_loss: 59.5630\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 45.4303 - val_loss: 52.0206\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 45.5458 - val_loss: 52.5082\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 49.4543 - val_loss: 56.3009\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 47.2430 - val_loss: 71.6745\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 48.7571 - val_loss: 56.6047\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 41.8310 - val_loss: 59.4385\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 46.1198 - val_loss: 71.4826\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 47.8858 - val_loss: 70.7962\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 45.7521 - val_loss: 71.0142\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 43.1500 - val_loss: 72.1500\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 42.3142 - val_loss: 64.9658\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 43.3667 - val_loss: 70.0720\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 48.8108 - val_loss: 57.8911\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 45.5436 - val_loss: 59.1401\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 42.9728 - val_loss: 58.8373\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 44.1522 - val_loss: 59.7714\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 40.9041 - val_loss: 66.9040\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 46.0668 - val_loss: 73.8792\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 42.2121 - val_loss: 63.4584\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 48.9878 - val_loss: 58.5858\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 40.9267 - val_loss: 63.0012\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 41.9581 - val_loss: 60.6504\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 42.6336 - val_loss: 55.6137\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 43.3319 - val_loss: 55.4930\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 43.7329 - val_loss: 61.3267\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 45.1768 - val_loss: 62.9810\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 43.7092 - val_loss: 65.4174\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 43.6197 - val_loss: 57.4153\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 44.1727 - val_loss: 52.1770\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 41.0872 - val_loss: 53.8952\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 41.4173 - val_loss: 57.5821\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38.2198 - val_loss: 55.2185\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 37.5996 - val_loss: 53.0899\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 42.6341 - val_loss: 53.4676\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 40.1879 - val_loss: 58.9397\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 37.6521 - val_loss: 57.9694\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 48.0788 - val_loss: 54.3983\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 38.8247 - val_loss: 56.1326\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 40.8182 - val_loss: 57.0906\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 39.8179 - val_loss: 59.1767\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 48.3199 - val_loss: 62.6417\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 40.8928 - val_loss: 62.2061\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 43.3847 - val_loss: 56.3993\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 40.2775 - val_loss: 58.3431\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 41.1494 - val_loss: 57.4449\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 37.5806 - val_loss: 62.6058\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 42.5972 - val_loss: 59.3574\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 41.1112 - val_loss: 57.6468\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 39.6356 - val_loss: 54.5895\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 44.2399 - val_loss: 58.6857\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 41.8971 - val_loss: 61.7359\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 42.8903 - val_loss: 59.5680\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 43.7151 - val_loss: 65.6140\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 38.9389 - val_loss: 66.0919\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38.6778 - val_loss: 64.3763\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 38.2709 - val_loss: 63.5470\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 45.9930 - val_loss: 57.7494\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 41.2279 - val_loss: 57.5026\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 40.9098 - val_loss: 59.3464\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 44.6134 - val_loss: 59.7440\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38.5769 - val_loss: 57.6206\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 37.2949 - val_loss: 57.8978\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 40.5935 - val_loss: 68.9438\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 39.3489 - val_loss: 66.4278\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38.1752 - val_loss: 68.8048\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 58.8815 - val_loss: 94.2976\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 46.8629 - val_loss: 63.4956\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38.3633 - val_loss: 62.0182\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 42.5770 - val_loss: 64.5279\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 38.4631 - val_loss: 55.9491\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38.9855 - val_loss: 137.4343\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 40.8696 - val_loss: 62.4851\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 43.7637 - val_loss: 57.1051\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 41.9220 - val_loss: 56.2664\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 44.7341 - val_loss: 63.8309\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 41.2782 - val_loss: 56.2891\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 41.2701 - val_loss: 72.6143\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 37.8814 - val_loss: 56.8906\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 44.8975 - val_loss: 62.9266\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 41.1173 - val_loss: 59.0324\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 43.0429 - val_loss: 60.0789\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 38.8838 - val_loss: 54.9072\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 39.7995 - val_loss: 56.3596\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 37.9361 - val_loss: 56.8466\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 40.2087 - val_loss: 57.7008\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 38.3307 - val_loss: 55.0157\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 36.1380 - val_loss: 75.3094\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 38.0957 - val_loss: 61.9993\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 38.4594 - val_loss: 55.8955\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 36.2627 - val_loss: 55.4612\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 36.3563 - val_loss: 58.6291\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 35.1603 - val_loss: 57.5555\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 36.2712 - val_loss: 58.8323\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 40.2681 - val_loss: 62.5493\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38.6879 - val_loss: 56.2217\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 35.1542 - val_loss: 55.3455\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 39.4396 - val_loss: 55.3222\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38.6301 - val_loss: 66.5249\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 36.5779 - val_loss: 53.0924\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 37.0008 - val_loss: 54.4830\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 34.9507 - val_loss: 56.2862\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 39.3757 - val_loss: 54.3255\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 38.0429 - val_loss: 50.9394\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 35.1046 - val_loss: 99.0467\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 35.5097 - val_loss: 100.5465\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 39.3747 - val_loss: 66.4760\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 56.4142 - val_loss: 73.4416\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 54.7747 - val_loss: 58.3303\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 52.2950 - val_loss: 74.9948\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 51.0865 - val_loss: 59.4713\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 44.0716 - val_loss: 61.9502\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 48.3419 - val_loss: 60.9727\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 46.4153 - val_loss: 57.4976\n",
            "[INFO] training model done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model: Sequential = load_model(MODEL_PATH_TO_SAVE)\n",
        "model.evaluate(test_images_x, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1C8iHrfi9gb",
        "outputId": "9565b65b-5fcd-4d10-e87e-abb0b779de38"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step - loss: 50.5028\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.5028076171875"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "JNVUKi_SfJ0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model_save_path: str, input_images_path: str) -> float:\n",
        "    # del model\n",
        "    model: Sequential = load_model(model_save_path)\n",
        "\n",
        "    images = []\n",
        "    output_image = np.zeros((64, 64, 3), dtype='uint8')\n",
        "\n",
        "    for img in os.listdir(input_images_path):\n",
        "        image = cv.imread(os.path.join(input_images_path, img))\n",
        "        image = cv.resize(image, (32, 32))\n",
        "        images.append(image)\n",
        "\n",
        "    output_image[0:32, 0:32] = images[0]\n",
        "    output_image[0:32, 32:64] = images[1]\n",
        "    output_image[32:64, 32:64] = images[2]\n",
        "    output_image[32:64, 0:32] = images[3]\n",
        "    output_image = cv.cvtColor(output_image, cv.COLOR_BGR2RGB)\n",
        "    plt.imshow(output_image)\n",
        "\n",
        "    output_image = np.array(output_image)\n",
        "    output_image = output_image / 255.\n",
        "\n",
        "    output_image = output_image.reshape(1, 64, 64, 3)\n",
        "    prediction = model.predict([output_image])\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "j6tDR7pzftal"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction: float = predict(MODEL_PATH_TO_SAVE, TEST_IMAGES_DIRECTORY)\n",
        "print(f'House price estimated: {prediction[0][0]}')"
      ],
      "metadata": {
        "id": "bmq2E2_jgUlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uG9E1ltxheCe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}